# -*- coding: utf-8 -*-
"""Image Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ek0124SmGVGCtvjXZO8YtYhMVqutgqxA

**Nama     : Daniel Sutan Sitompul**
**Username : Clock11**
**Email    : vss10124@gmail.com**
**Provinsi : Jambi**
"""

pip install split-folders

"""Setup dan Import Library

"""

import warnings
warnings.filterwarnings('ignore')


import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import scipy as sp
import itertools
import splitfolders
import zipfile,os
import cv2

"""Import Library TensorFlow, Keras dan Masukkan Dataset"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, Flatten, MaxPool2D
from tensorflow.keras.optimizers import Adam, RMSprop
from sklearn.model_selection import train_test_split

print(tf.__version__)

!wget --no-check-certificate \https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip

"""Memisahkan Data Latih dan Validasi

"""

local_zip = 'rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip,'r')
zip_ref.extractall('/content')
zip_ref.close()

splitfolders.ratio('/content/rockpaperscissors/rps-cv-images', output="/content/rockpaperscissors/", seed=1337, ratio=(0.6, 0.4))
splitfolders.fixed('/content/rockpaperscissors/rps-cv-images', output="/content/rockpaperscissors/", seed=1337, fixed=(100, 100), oversample=False)

data_dir = '/content/rockpaperscissors/'
training_dir = os.path.join(data_dir, 'train')
validation_dir = os.path.join(data_dir, 'val')
roc_dir = os.path.join(base_dir,'rock')
pap_dir = os.path.join(base_dir, 'paper')
sci_dir = os.path.join(base_dir, 'scissors')

print(len(os.listdir('/content/rockpaperscissors/paper')))
print(len(os.listdir('/content/rockpaperscissors/rock')))
print(len(os.listdir('/content/rockpaperscissors/scissors')))

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.97):
      print("\nAkurasi di atas 97%, hentikan training!")
      self.model.stop_training = True

callbacks = myCallback()

os.mkdir(training_dir)
os.mkdir(validation_dir)

training_paper_dir = os.path.join(training_dir, 'paper')
training_rock_dir = os.path.join(training_dir, 'rock')
training_scissors_dir = os.path.join(training_dir, 'scissors')

validation_paper_dir = os.path.join(validation_dir, 'paper')
validation_rock_dir = os.path.join(validation_dir, 'rock')
validation_scissors_dir = os.path.join(validation_dir, 'scissors')

base_dir = '/tmp/rockpaperscissors'
train_dir = os.path.join(base_dir,'train')
validation_dir = os.path.join(base_dir, 'val')
roc_dir = os.path.join(base_dir,'rock')
pap_dir = os.path.join(base_dir, 'paper')
sci_dir = os.path.join(base_dir, 'scissors')

training_rock_dir, validation_paper_dir = train_test_split(os.listdir(roc_dir), test_size = 0.40)
training_paper_dir, val_pap_dir = train_test_split(os.listdir(pap_dir), test_size = 0.40)
training_scissors_dir, validation_scissors_dir = train_test_split(os.listdir(sci_dir), test_size = 0.40)

paper_imgs = os.listdir(training_paper_dir)
rock_imgs = os.listdir(training_rock_dir)
scissors_imgs = os.listdir(training_scissors_dir)

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(paper_imgs[:5]):
    sp = plt.subplot(1, 5, i+1)
    img = mpimg.imread(os.path.join(training_paper_dir, img_path))
    plt.imshow(img)
plt.show()

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(rock_imgs[:5]):
    sp = plt.subplot(1, 5, i+1)
    img = mpimg.imread(os.path.join(training_rock_dir, img_path))
    plt.imshow(img)
plt.show()

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(scissors_imgs[:5]):
    sp = plt.subplot(1, 5, i+1)
    img = mpimg.imread(os.path.join(training_scissors_dir, img_path))
    plt.imshow(img)
plt.show()

train_datagen = ImageDataGenerator(
    rescale= 1./255,
    validation_split= 0.6,
    shear_range = 0.2,
    zoom_range= 0.2,
    rotation_range= 20,
    fill_mode = 'nearest',
    horizontal_flip=True
    )

validation_datagen = ImageDataGenerator(
    rescale=1./255,
    fill_mode = 'nearest',
    validation_split= 0.4)

train_generator = train_datagen.flow_from_directory(
            training_dir,
            target_size=(100,100),
            batch_size=32,
            class_mode='categorical',
            shuffle=True
)

valid_generator = validation_datagen.flow_from_directory(
            validation_dir,
            target_size=(100,100),
            batch_size=32,
            class_mode='categorical',
            shuffle=True,
            subset='validation'
)

train_generator.class_indices

valid_generator.class_indices

model = Sequential()

model.add(Conv2D(16, kernel_size=3, activation='relu', input_shape=(100, 100, 3)))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(32, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(64, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(128, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.summary()

model.compile(optimizer = 'RMSprop',
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

BATCH_SIZE = 32
EPOCHS = 20

history = model.fit(train_generator,
          steps_per_epoch=BATCH_SIZE,
          epochs=EPOCHS,
          validation_data=valid_generator,
          validation_steps=5,
          verbose=2)

"""Evaluasi Model"""

score = model.evaluate(train_generator)

print('Loss: {:.4f}'.format(score[0]))
print('Accuracy: {:.4f}'.format(score[1]))

score = model.evaluate(valid_generator)

print('Loss: {:.4f}'.format(score[0]))
print('Accuracy: {:.4f}'.format(score[1]))

RPS_SAVED_MODEL = "rps_saved_model"

tf.saved_model.save(model, RPS_SAVED_MODEL)

"""Plot Kurva Data Latih dan Validasi"""

import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(EPOCHS)

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='upper right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

acc2 = history.history['accuracy']
val_acc2 = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc2))

plt.figure(figsize=(12, 4))
plt.plot(epochs, acc2, 'r', label='Training accuracy')
plt.plot(epochs, val_acc2, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc='upper right')
plt.figure()


plt.show()

"""Confusion Matrix"""

from sklearn.metrics import classification_report, confusion_matrix
import sklearn.metrics

Y_pred = model.predict(valid_generator, BATCH_SIZE+1)
y_pred = np.argmax(Y_pred, axis=1)

print('Confusion Matrix')
print(confusion_matrix(valid_generator.classes, y_pred))
confusion_array = sklearn.metrics.confusion_matrix(valid_generator.classes, y_pred)

print('True Negative = ', confusion_array[0,0])
print('False Negative = ', confusion_array[1,0])
print('True Positive = ', confusion_array[1,1])
print('False Positive = ', confusion_array[0,1])

"""Classification Report & Rekapitulasi Hasil Data"""

print('Classification Report')
target_names = ['Paper', 'Rock', 'Scissors']
print(classification_report(valid_generator.classes, y_pred, target_names=target_names))

import pandas as pd

evaluation = pd.DataFrame({'Model': [],
                           'Data_Train': [],
                           'Data_Valid': [],
                           'Epochs': [],
                           'Batch_Size': [],
                           'Loss': [],
                           'Accuracy': []
})

r = evaluation.shape[0]
evaluation.loc[r] = ['CNN', train_generator.n, valid_generator.n, EPOCHS, BATCH_SIZE, score[0], score[1]]
evaluation

dict = {"Model" : evaluation.Model,
        "Data Train" : evaluation.Data_Train,
        "Data Valid" : evaluation.Data_Valid,
        "Epochs" : evaluation.Epochs,
        "Batch Size" : evaluation.Batch_Size,
        "Loss" : evaluation.Loss,
        "Accuracy" : evaluation.Accuracy}

"""Memprediksi Model Data yang ada dengan Upload Gambar"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import files
from keras.preprocessing import image
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():


  path = fn
  img = image.load_img(path, target_size=(100,100))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=32)

  print(fn)
  if classes[0,0] == 1.0:
    print('Paper')
  elif classes[0,1] == 1.0:
    print('Rock')
  else:
    print('Scissors')